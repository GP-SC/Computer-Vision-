{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "kqso0bOYfZbK"
      },
      "outputs": [],
      "source": [
        "from skimage.feature import hog\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import exposure\n",
        "import sys\n",
        "class Image:\n",
        "    def __init__(self, img, label):\n",
        "        self.img = img\n",
        "        self.label = label\n",
        "\n",
        "def Load_Dataset():\n",
        "    currpath=\"Data/Product Classification\"\n",
        "    Classes=os.listdir(currpath)\n",
        "    Classes.sort( key=lambda x: int(x))\n",
        "    Classes=list(map(lambda x:currpath+\"/\"+x,Classes))\n",
        "    X_train,y_train,X_valid,y_valid= [], [], [], []\n",
        "    trainset=[]\n",
        "    validset=[]\n",
        "    mx=(0,0)\n",
        "    for Class in Classes:\n",
        "        trainpart=os.listdir(Class+\"/\"+\"Train\")\n",
        "        trainpart=list(map(lambda x:Class+\"/\"+\"Train\"+\"/\"+x,trainpart))\n",
        "        for file in trainpart:\n",
        "            img=cv2.imread(file,0)\n",
        "            label=Class.split(\"/\")[-1]\n",
        "            mx=max(mx,img.shape)\n",
        "            trainset.append(Image(img,label))\n",
        "            X_train.append(img)\n",
        "            y_train.append(label)\n",
        "        if \"Validation\"  not in os.listdir(Class):continue\n",
        "        validpart=os.listdir(Class+\"/\"+\"Validation\")\n",
        "        validpart=list(map(lambda x:Class+\"/\"+\"Validation\"+\"/\"+x,validpart))\n",
        "        for file in validpart:\n",
        "            img=cv2.imread(file,0)\n",
        "            label=Class.split(\"/\")[-1]\n",
        "            validset.append(Image(img,label))\n",
        "            X_valid.append(img)\n",
        "            y_valid.append(label)\n",
        "    return trainset,validset,X_train,y_train,X_valid,y_valid\n",
        "\n",
        "\n",
        "def preprocessing(DataSet):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "\n",
        "    for image in DataSet:\n",
        "        img = image.img\n",
        "        # Resize the image\n",
        "        # Normalize the image\n",
        "        normalized_image = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
        "        # Gaussian Blur\n",
        "        blurred_image = normalized_image\n",
        "        blurred_image=cv2.resize(blurred_image,(128,128))\n",
        "        processed_images.append(blurred_image)\n",
        "        labels.append(image.label)\n",
        "\n",
        "    return processed_images, labels\n",
        "\n",
        "    \n",
        "def read_files_in_folder(folder_path):\n",
        "    try:\n",
        "        X_test = []\n",
        "        y_test = []\n",
        "        testset= []\n",
        "        for label, class_name in enumerate(os.listdir(folder_path)):\n",
        "            class_path = os.path.join(folder_path, class_name)\n",
        "            for file_name in os.listdir(class_path):\n",
        "                file_path = os.path.join(class_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    image = cv2.imread(file_path,0)\n",
        "                    X_test.append(image)\n",
        "                    y_test.append(class_name)\n",
        "                    testset.append(Image(image,label))\n",
        "        print(\"Hog Started\")\n",
        "        \n",
        "        #    Step 3: HOG Feature Extraction\n",
        "        X_test,y_test = preprocessing(testset)\n",
        "        print(\"imgShape\")\n",
        "        print(X_test[0].shape)\n",
        "        for i,image in enumerate(X_test) :\n",
        "        # Calculate HOG features for each image\n",
        "            if i==0:\n",
        "                 features, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "                 Test_hog_features =np.array(features) \n",
        "                 continue\n",
        "            features, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "            Test_hog_features=np.vstack((Test_hog_features,features))\n",
        "        \n",
        "        print(\"Hog Ended\")\n",
        "\n",
        "        return testset,Test_hog_features,y_test    \n",
        "    except OSError as e:\n",
        "        print(f\"Error reading files in {folder_path}: {e}\")\n",
        "    \n",
        "\n",
        "\n",
        "trainset,validset,X_train,y_train,X_valid,y_valid=Load_Dataset()\n",
        "X_train_processed, y_train_processed = preprocessing(trainset)\n",
        "\n",
        "X_valid_processed, y_valid_processed = preprocessing(validset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "oPjvJJxzfbjc"
      },
      "outputs": [],
      "source": [
        "trainset,validset,X_train,y_train,X_valid,y_valid=Load_Dataset()\n",
        "X_train_processed, y_train_processed = preprocessing(trainset)\n",
        "X_valid_processed, y_valid_processed = preprocessing(validset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_valid_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hog Started\n",
            "Hog Ended\n",
            "Hog Started\n",
            "Hog Ended\n",
            "Hog Started\n",
            "imgShape\n",
            "(128, 128)\n",
            "Hog Ended\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a dataset 'images' and corresponding 'labels'\n",
        "Train_images=X_train_processed\n",
        "Train_labels=y_train_processed\n",
        "\n",
        "Valid_images=X_valid_processed\n",
        "Valid_labels=y_valid_processed\n",
        "\n",
        "print(\"Hog Started\")\n",
        "# Step 3: HOG Feature Extraction\n",
        " \n",
        "for i,image in enumerate(Train_images) :\n",
        "    # Calculate HOG features for each image\n",
        "    if i==0:\n",
        "        features, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "        Train_hog_features =np.array(features)\n",
        "        continue\n",
        "    features, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "    Train_hog_features=np.vstack((Train_hog_features,features))\n",
        "print(\"Hog Ended\")\n",
        "\n",
        "\n",
        "print(\"Hog Started\")\n",
        "Valid_hog_features = []\n",
        "for i,image in enumerate(Valid_images):\n",
        "    # Calculate HOG features for each image\n",
        "    if i==0:\n",
        "        features, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                              cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "        Valid_hog_features =np.array(features)\n",
        "        continue\n",
        "    features, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                              cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "    Valid_hog_features=np.vstack((Valid_hog_features,features))    \n",
        "    # Calculate HOG features for each image\n",
        " \n",
        "print(\"Hog Ended\")\n",
        "testset,X_test,y_test=read_files_in_folder(\"E:/4th year projects/cv/Test Samples Classification/Test Samples Classification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Training\n",
            "SVM Trained\n",
            "Accuracy Train: 1.0\n",
            "Accuracy Train: 0.5882352941176471\n",
            "Accuracy Train: 0.047619047619047616\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Train-test Split\n",
        "X_train, X_Valid, y_train, y_valid = np.array(Train_hog_features),np.array(Valid_hog_features),np.array(Train_labels,dtype=int),np.array(Valid_labels,dtype=int)\n",
        "\n",
        "print(\"SVM Training\")\n",
        "# Step 6: SVM Model Training\n",
        "svm_model = svm.SVC(kernel='rbf',random_state=2002,C=100)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"SVM Trained\")\n",
        "\n",
        "# Step 7: Testing and Evaluation\n",
        "y_pred = svm_model.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(\"Accuracy Train:\", accuracy)\n",
        "\n",
        "y_pred = svm_model.predict(X_Valid)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "print(\"Accuracy Train:\", accuracy)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Train:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
